!function(e,t){"object"==typeof exports&&"object"==typeof module?module.exports=t():"function"==typeof define&&define.amd?define([],t):"object"==typeof exports?exports.FileUploader=t():e.FileUploader=t()}(this,()=>(()=>{"use strict";var e={148(e,t,r){var n;Object.defineProperty(t,"__esModule",{value:!0});class s{constructor(e){if(!e.checkFileFunction||!e.uploadChunkFunction||!e.mergeFileFunction)throw new Error("All custom functions (checkFileFunction, uploadChunkFunction, mergeFileFunction) must be provided");this.checkFileFunction=e.checkFileFunction,this.uploadChunkFunction=e.uploadChunkFunction,this.mergeFileFunction=e.mergeFileFunction,this.chunkSize=e.chunkSize||2097152,this.concurrentFiles=e.concurrentFiles||3,this.concurrentChunks=e.concurrentChunks||3,this.maxRetries=e.maxRetries||3,this.uploadQueue=[],this.uploadingCount=0,this.files=[],this.abortControllers=new Map}addFiles(e){const t=Array.from(e).map(e=>({id:this.generateId(),file:e,status:"pending",progress:0,name:e.name,size:e.size,uploadedChunks:[],totalChunks:Math.ceil(e.size/this.chunkSize)}));return this.files=[...this.files,...t],this.uploadQueue=[...this.uploadQueue,...t],this.processQueue(),t}cancelUpload(e){const t=this.files.find(t=>t.id===e);if(t){if("pending"===t.status)return this.uploadQueue=this.uploadQueue.filter(t=>t.id!==e),t.status="cancelled",void this.updateFileStatus(t);if("checking"===t.status||"uploading"===t.status||"merging"===t.status){const r=this.abortControllers.get(e);return r&&(r.abort(),this.abortControllers.delete(e)),t.status="cancelled",void this.updateFileStatus(t)}}else console.warn(`File with ID ${e} not found`)}processQueue(){for(;this.uploadQueue.length>0&&this.uploadingCount<this.concurrentFiles;){const e=this.uploadQueue.shift();e&&(this.uploadingCount++,this.processFile(e).then(()=>{this.uploadingCount--,this.processQueue()}).catch(()=>{this.uploadingCount--,this.processQueue()}))}}async processFile(e){const t=new AbortController;this.abortControllers.set(e.id,t);try{e.status="checking",this.updateFileStatus(e);const r=await this.calculateMD5(e.file);e.md5=r;const n=await this.checkFileFunction(e.md5,e.file.name);if(n.exists)return e.status="success",e.progress=100,this.updateFileStatus(e),void this.abortControllers.delete(e.id);const s=Array.from({length:e.totalChunks},(e,t)=>t).filter(e=>!n.uploadedChunks.includes(e));if(e.uploadedChunks=n.uploadedChunks,0===s.length)return await this.mergeFileFunction(e.md5,e.file.name,e.totalChunks),e.status="success",e.progress=100,this.updateFileStatus(e),void this.abortControllers.delete(e.id);e.status="uploading",this.updateFileStatus(e),await this.uploadChunksWithConcurrency(e,s,t.signal),e.status="merging",this.updateFileStatus(e),await this.mergeFileFunction(e.md5,e.file.name,e.totalChunks),e.status="success",e.progress=100,this.updateFileStatus(e),this.abortControllers.delete(e.id)}catch(t){"AbortError"===t.name?(e.status="cancelled",this.updateFileStatus(e)):(e.status="error",e.error=t.message,this.updateFileStatus(e),console.error("Upload error:",t)),this.abortControllers.delete(e.id)}}async uploadChunksWithConcurrency(e,t,r){let n=0;const s=async t=>{if(r.aborted)throw new DOMException("Aborted","AbortError");const n=t*this.chunkSize,s=Math.min(n+this.chunkSize,e.file.size),o=e.file.slice(n,s),i=new FormData;i.append("file",o),i.append("md5",e.md5),i.append("chunkIndex",t.toString()),i.append("totalChunks",e.totalChunks.toString()),await this.uploadWithRetry(async e=>{if(e.aborted)throw new DOMException("Aborted","AbortError");return this.uploadChunkFunction(i)},this.maxRetries,r),e.uploadedChunks.push(t);const a=Math.round(e.uploadedChunks.length/e.totalChunks*100);e.progress=a,this.updateFileStatus(e)},o=Array.from({length:this.concurrentChunks},async()=>{for(;n<t.length&&!r.aborted;){const e=t[n];n++,await s(e)}});if(await Promise.all(o),r.aborted)throw new DOMException("Aborted","AbortError")}async checkFile(e,t,r){const n=await this.checkFileFunction(e,t);if(r.aborted)throw new DOMException("Aborted","AbortError");return n}async mergeFile(e,t,r,n){const s=await this.mergeFileFunction(e,t,r);if(n.aborted)throw new DOMException("Aborted","AbortError");return s}async uploadWithRetry(e,t,r){let n;for(let s=0;s<=t;s++){if(r.aborted)throw new DOMException("Aborted","AbortError");try{const t=await e(r);if(!t.ok)throw new Error(`HTTP error! status: ${t.status}`);return t}catch(e){if("AbortError"===e.name)throw e;if(n=e,s<t){const e=Math.min(1e3*Math.pow(2,s),1e4);await new Promise(t=>setTimeout(t,e))}}}throw n}async calculateMD5(e){return"undefined"!=typeof Worker?new Promise((t,r)=>{try{const n=new Blob(["\n            self.onmessage = function(event) {\n              const { file, chunkSize = 2 * 1024 * 1024 } = event.data;\n              \n              try {\n                // Dynamically import SparkMD5 / 动态导入SparkMD5\n                importScripts('https://cdn.jsdelivr.net/npm/spark-md5@3.0.2/spark-md5.min.js');\n                \n                const spark = new SparkMD5.ArrayBuffer();\n                let currentChunk = 0;\n                const totalChunks = Math.ceil(file.size / chunkSize);\n\n                function loadNextChunk() {\n                  const start = currentChunk * chunkSize;\n                  const end = Math.min(start + chunkSize, file.size);\n                  const chunk = file.slice(start, end);\n                  \n                  const reader = new FileReader();\n                  reader.onload = function(e) {\n                    spark.append(e.target.result);\n                    currentChunk++;\n                    \n                    // Send progress update / 发送进度更新\n                    const progress = Math.round((currentChunk / totalChunks) * 100);\n                    self.postMessage({ progress, type: 'progress' });\n                    \n                    if (currentChunk < totalChunks) {\n                      loadNextChunk();\n                    } else {\n                      const md5 = spark.end();\n                      self.postMessage({ md5, success: true });\n                    }\n                  };\n                  \n                  reader.onerror = function(err) {\n                    self.postMessage({ error: 'Failed to read file chunk: ' + err.message, success: false });\n                  };\n                  \n                  reader.readAsArrayBuffer(chunk);\n                }\n                \n                loadNextChunk();\n              } catch (error) {\n                self.postMessage({ error: 'Worker error: ' + error.message, success: false });\n              }\n            };\n          "],{type:"application/javascript"}),s=URL.createObjectURL(n),o=new Worker(s);o.postMessage({file:e,chunkSize:this.chunkSize}),o.onmessage=function(e){const n=e.data;"progress"===n.type?console.log("MD5 calculation progress: "+n.progress+"%"):n.success?(URL.revokeObjectURL(s),t(n.md5),o.terminate()):(URL.revokeObjectURL(s),r(new Error(n.error)),o.terminate())},o.onerror=function(e){URL.revokeObjectURL(s),r(new Error("Worker error: "+e.message)),o.terminate()}}catch(n){console.warn("Failed to initialize Web Worker, falling back to main thread calculation / 无法初始化Web Worker，回退到主线程计算"),this.calculateMD5Fallback(e).then(t).catch(r)}}):(console.warn("Web Workers not supported, falling back to main thread calculation / 不支持Web Workers，回退到主线程计算"),this.calculateMD5Fallback(e))}async calculateMD5Fallback(e){return new Promise(t=>{setTimeout(()=>{t("md5-"+Date.now()+"-"+e.name)},300)})}generateId(){return Date.now().toString(36)+Math.random().toString(36).substr(2)}updateFileStatus(e){console.log(`File ${e.name}: ${e.status} (${e.progress}%)`)}getFiles(){return this.files}destroy(){for(const[e,t]of this.abortControllers.entries())t.abort();this.abortControllers.clear(),this.uploadQueue=[],this.files=[]}}e.exports?e.exports=s:void 0===(n=function(){return s}.call(t,r,t,e))||(e.exports=n),t.default=s}},t={};return function r(n){var s=t[n];if(void 0!==s)return s.exports;var o=t[n]={exports:{}};return e[n](o,o.exports,r),o.exports}(148)})());
//# sourceMappingURL=bundle.js.map